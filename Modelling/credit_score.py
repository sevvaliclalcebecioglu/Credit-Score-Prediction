# %%
# 1. Import Libraries

import pandas as pd 

from sklearn.model_selection import train_test_split  # Veriyi eÄŸitim ve test olarak ayÄ±rmak iÃ§in gerekli fonksiyon

from sklearn.naive_bayes import GaussianNB  # SÃ¼rekli sayÄ±sal veriler iÃ§in Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±

from sklearn.naive_bayes import BernoulliNB  # Binary (0/1) veriler iÃ§in Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  
# Model performansÄ±nÄ± Ã¶lÃ§mek iÃ§in; doÄŸruluk, karÄ±ÅŸÄ±klÄ±k matrisi ve detaylÄ± sÄ±nÄ±flandÄ±rma raporu

from sklearn.metrics import roc_auc_score, roc_curve
# ROC AUC skoru ve ROC eÄŸrisi iÃ§in gerekli metrikler

from sklearn.tree import DecisionTreeClassifier  # Karar aÄŸacÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±

from sklearn.ensemble import RandomForestClassifier  # Rastgele orman (birden fazla karar aÄŸacÄ±) sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±

from sklearn.neighbors import KNeighborsClassifier  # K-en yakÄ±n komÅŸu algoritmasÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±

from sklearn.ensemble import GradientBoostingClassifier  # Gradyan artÄ±rÄ±mlÄ± karar aÄŸacÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±

from sklearn.linear_model import LogisticRegression  # Lojistik regresyon sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± (0/1 tahmini)

# %%
# 2. Load Clean Data

df = pd.read_csv('../data/clean_train.csv')

df.head()

# 3. Modeling
# %%
# x, y ayrÄ±mÄ±

x = df.drop('Credit_Score', axis=1)  # Ã–zellikler (baÄŸÄ±msÄ±z deÄŸiÅŸkenler)
y = df['Credit_Score']  # Hedef deÄŸiÅŸken (baÄŸÄ±mlÄ± deÄŸiÅŸken)

# %%
# get_dummies ile kategorik deÄŸiÅŸkenleri sayÄ±sal hale getirme

x = pd.get_dummies(x, drop_first=True)

x.head()        

# %%
# Veriyi eÄŸitim ve test olarak ayÄ±rma

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)  

# Veriyi eÄŸitim ve test olarak ayÄ±rÄ±yoruz
# x -> Ã¶zellikler (features), y -> hedef deÄŸiÅŸken (target)
# test_size=0.15 -> verinin %15'i test iÃ§in ayrÄ±lÄ±r, %85'i eÄŸitim iÃ§in
# random_state=42 -> veriyi her Ã§alÄ±ÅŸtÄ±rmada aynÄ± ÅŸekilde bÃ¶lmek iÃ§in sabit sayÄ±

# %%
# Lojistik Regresyon Modeli

L = LogisticRegression()  
# Lojistik Regresyon modelini oluÅŸturuyoruz (sÄ±nÄ±flandÄ±rma iÃ§in, 0/1 tahmini)

L.fit(x_train, y_train)  
# Modeli eÄŸitim verisi ile eÄŸitiyoruz

Ltahmin = L.predict(x_test)  
# Test verisi Ã¼zerinde tahmin yapÄ±yoruz

accuracy_score(y_test, Ltahmin)  
# Modelin doÄŸruluk (accuracy) skorunu hesaplÄ±yoruz

confusion_matrix(y_test, Ltahmin)  
# KarÄ±ÅŸÄ±klÄ±k matrisini hesaplÄ±yoruz (gerÃ§ek vs tahmin deÄŸerleri)

print(classification_report(y_test, Ltahmin))  
# DetaylÄ± sÄ±nÄ±flandÄ±rma raporu: precision, recall, f1-score ve support

# %%
# Algo Test

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split


def algo_test(x, y):
    """
    FarklÄ± sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ± test eder ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r.
    Multiclass hedef deÄŸiÅŸkeni destekler ve F1 skorlarÄ±na gÃ¶re sÄ±ralama yapar.
    """
    # Modeller
    models = [
        GaussianNB(),
        LogisticRegression(max_iter=1000),
        DecisionTreeClassifier(random_state=42),
        RandomForestClassifier(random_state=42),
        GradientBoostingClassifier(random_state=42),
        KNeighborsClassifier(),
        AdaBoostClassifier(random_state=42)
    ]

    names = [
        "GaussianNB",
        "LogisticRegression",
        "DecisionTree",
        "RandomForest",
        "GradientBoosting",
        "KNN",
        "AdaBoost"
    ]

    # Veri setini ayÄ±r
    x_train, x_test, y_train, y_test = train_test_split(
        x, y, test_size=0.20, random_state=42, stratify=y
    )

    results = []

    print("ğŸš€ Modeller eÄŸitiliyor...\n")

    for model, name in zip(models, names):
        model.fit(x_train, y_train)
        y_pred = model.predict(x_test)

        # Ã‡ok sÄ±nÄ±flÄ± uyumlu skorlar
        results.append({
            "Model": name,
            "Accuracy": accuracy_score(y_test, y_pred),
            "Precision": precision_score(y_test, y_pred, average='weighted', zero_division=0),
            "Recall": recall_score(y_test, y_pred, average='weighted', zero_division=0),
            "F1": f1_score(y_test, y_pred, average='weighted', zero_division=0)
        })

        print(f"ğŸ”¹ {name} SonuÃ§larÄ±:")
        print(confusion_matrix(y_test, y_pred))
        print(classification_report(y_test, y_pred, digits=4))
        print("-" * 50)

    # DataFrame
    results_df = pd.DataFrame(results)
    results_df.sort_values(by="F1", ascending=False, inplace=True)

    # En iyi model
    best_model_name = results_df.iloc[0]["Model"]
    print("\nğŸ† En baÅŸarÄ±lÄ± model:", best_model_name)

    return results_df

# Algo Test'i Ã§alÄ±ÅŸtÄ±r ve sonuÃ§larÄ± kaydet
results_df = algo_test(x, y)

# xlsx olarak kaydet
results_df.to_excel("model_results.xlsx", index=False)
print("ğŸ“‚ Model sonuÃ§larÄ± kaydedildi: model_results.xlsx")

# %%
# RandomForestClassifier

import joblib

best_model = RandomForestClassifier(random_state=42)

best_model.fit(x, y)  # tÃ¼m veri ile yeniden eÄŸit

# Modeli kaydet
joblib.dump(best_model, "random_forest_model.pkl")
print("ğŸ“‚ En iyi model kaydedildi: random_forest_model.pkl")


# EÄŸitim sÄ±rasÄ±nda kullanÄ±lan feature kolonlarÄ±nÄ± kaydet
joblib.dump(x.columns.tolist(), "columns.pkl")








